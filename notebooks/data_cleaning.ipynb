{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3ed1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "\n",
      " Dataset Shape: (9994, 21)\n",
      "\n",
      " Columns and Data Types:\n",
      "Row ID             int64\n",
      "Order ID          object\n",
      "Order Date        object\n",
      "Ship Date         object\n",
      "Ship Mode         object\n",
      "Customer ID       object\n",
      "Customer Name     object\n",
      "Segment           object\n",
      "Country           object\n",
      "City              object\n",
      "State             object\n",
      "Postal Code        int64\n",
      "Region            object\n",
      "Product ID        object\n",
      "Category          object\n",
      "Sub-Category      object\n",
      "Product Name      object\n",
      "Sales            float64\n",
      "Quantity           int64\n",
      "Discount         float64\n",
      "Profit           float64\n",
      "dtype: object\n",
      "\n",
      " Missing Values:\n",
      "Row ID           0\n",
      "Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "Quantity         0\n",
      "Discount         0\n",
      "Profit           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Script name: data_cleaning.ipynb\n",
    "Author: Md Golam Mohiuddin\n",
    "Description: This scripts loads the data file in dataset, and do cleaning on top of it.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "DATA_PATH = \"../data/Superstore.csv\"\n",
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads the dataset from the given path.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path, encoding='utf-8')\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found.\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading dataset: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to get basic info of the dataset\n",
    "def inspect_dataset(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Displays basic structure and null value summary of the dataset.\"\"\"\n",
    "    print(\"\\n Dataset Shape:\", df.shape)\n",
    "    print(\"\\n Columns and Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n Missing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "# Load and inspect the dataset\n",
    "df_superstore = load_dataset(DATA_PATH)\n",
    "if not df_superstore.empty:\n",
    "    inspect_dataset(df_superstore)\n",
    "    # Save first few rows for reference\n",
    "    df_superstore.head().to_csv(\"../data/sample_preview.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb6c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Removed 0 duplicate rows.\n",
      "Cleaned data saved as 'Superstore_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Convert date columns to datetime\n",
    "def convert_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Converts order and ship dates to datetime format.\"\"\"\n",
    "    df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce')\n",
    "    df['Ship Date'] = pd.to_datetime(df['Ship Date'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Create new date-based columns\n",
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds order month and order year columns.\"\"\"\n",
    "    df['Order Month'] = df['Order Date'].dt.month\n",
    "    df['Order Year'] = df['Order Date'].dt.year\n",
    "    return df\n",
    "\n",
    "# Create profit margin column\n",
    "def add_profit_margin(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculates profit margin (Profit/Sales).\"\"\"\n",
    "    df['Profit Margin'] = (df['Profit'] / df['Sales']).round(2)\n",
    "    return df\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Removes duplicate rows from the dataset.\"\"\"\n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates()\n",
    "    after = df.shape[0]\n",
    "    print(f\"ðŸ§¹ Removed {before - after} duplicate rows.\")\n",
    "    return df\n",
    "\n",
    "# Apply all cleaning functions\n",
    "df_superstore = convert_dates(df_superstore)\n",
    "df_superstore = add_time_features(df_superstore)\n",
    "df_superstore = add_profit_margin(df_superstore)\n",
    "df_superstore = remove_duplicates(df_superstore)\n",
    "\n",
    "# Save cleaned dataset for next steps\n",
    "df_superstore.to_csv(\"../data/Superstore_cleaned.csv\", index=False)\n",
    "print(\"Cleaned data saved as 'Superstore_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5bf617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
